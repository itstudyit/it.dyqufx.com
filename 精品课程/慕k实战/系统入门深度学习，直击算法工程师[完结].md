# 系统入门深度学习，直击算法工程师[完结]

## 联系方式

客服微信号：itziyuan_xiaozhi

<img src="https://ziyuanyun.oss-cn-guangzhou.aliyuncs.com/common/20240614073449/666b82192834a.jpg" width="200" height="200" alt="二维码">

## 课程简介

下载链接：https://it.bcwex.shop/posts?id=932

<img src="https://ziyuanyun.oss-cn-guangzhou.aliyuncs.com/yun/20240515153436/6644658c4c849.jpg" width="500" alt="">

  ┣━mksz547-系统入门深度学习，直击算法工程师[完结](1)

 ┣━第8章 数据不够怎么办？迁移学习来帮忙

 ┣━8-1 本章内容介绍.mp4

 ┣━8-4 怎么实施迁移学习？.mp4

 ┣━8-5 基于ResNet迁移学习的姿势识别.mp4

 ┣━8-2 什么是迁移学习.mp4

 ┣━8-8 inference.mp4

 ┣━8-7 工程代码（下）.mp4

 ┣━8-3 迁移学习分类.mp4

 ┣━8-6 工程代码（上）.mp4

 ┣━8-9 本章总结.mp4

 ┣━第5章 为序列数据而生：RNN系列

 ┣━5-12 基于双层、双向GRU的命令词识别模型搭建（2）.mp4

 ┣━5-10 GRU实现唤醒词识别.mp4

 ┣━5-4 循环神经网络原理.mp4

 ┣━5-15 基于双层、双向GRU的命令词识别模型搭建（5）.mp4

 ┣━5-13 基于双层、双向GRU的命令词识别模型搭建（3）.mp4

 ┣━5-2 什么是序列模型.mp4

 ┣━5-3 不同的RNN应用类型：OvM, MvM.mp4

 ┣━5-11 基于双层、双向GRU的命令词识别模型搭建（1）.mp4

 ┣━5-17 本章总结.mp4

 ┣━5-6 两个重要的变体：LSTMGRU（上）.mp4

 ┣━5-14 基于双层、双向GRU的命令词识别模型搭建（4）.mp4

 ┣━5-16 模型评估和选择.mp4

 ┣━5-9 典型应用范式：Encoder-Decoder.mp4

 ┣━5-5 用BPTT 训练RNN.mp4

 ┣━5-7 两个重要的变体：LSTMGRU（下）.mp4

 ┣━5-8 利用双向、多层RNN增强模型.mp4

 ┣━5-1 本章内容介绍.mp4

 ┣━资料

 ┣━课程资料.zip

 ┣━第6章 深度学习新思路： GAN网络

 ┣━6-11 超参和dataset编写.mp4

 ┣━6-9 GAN的一些变体之：text-to-image.mp4

 ┣━6-4 GAN的原理（下）.mp4

 ┣━6-6 GAN的一些变体之：StyleGAN（上）.mp4

 ┣━6-16 trainer 编写（3）.mp4

 ┣━6-2 什么是生成式模型？.mp4

 ┣━6-19 本章总结.mp4

 ┣━6-7 GAN的一些变体之：StyleGAN（下）.mp4

 ┣━6-5 GAN的一些变体之：CycleGAN.mp4

 ┣━6-10 用DCGAN生成人脸照片.mp4

 ┣━6-8 GAN的一些变体之：DCGAN.mp4

 ┣━6-12 generator编写.mp4

 ┣━6-14 trainer 编写（1）.mp4

 ┣━6-17 trainer 编写（4）.mp4

 ┣━6-1 本章内容介绍.mp4

 ┣━6-18 怎么检查GAN的训练过程？.mp4

 ┣━6-13 discriminator编写.mp4

 ┣━6-3 GAN的原理（上）.mp4

 ┣━6-15 trainer 编写（2）.mp4

 ┣━第2章 入门必修：单、多层感知机

 ┣━2-10 项目构建和模型训练（1）.mp4

 ┣━2-5 逻辑回归示例.mp4

 ┣━2-9 数据集及特征分析.mp4

 ┣━2-4 逻辑回归损失函数.mp4

 ┣━2-13 项目构建和模型训练（4）.mp4

 ┣━2-8 基于多层DNN假钞识别.mp4

 ┣━2-11 项目构建和模型训练（2）.mp4

 ┣━2-7 pytorch 构建单多层感知机.mp4

 ┣━2-3 逻辑回归.mp4

 ┣━2-2 深度学习实施的一般过程.mp4

 ┣━2-14 模型评估和选择.mp4

 ┣━2-15 本章总结.mp4

 ┣━2-12 项目构建和模型训练（3）.mp4

 ┣━2-6 单层、多层感知机.mp4

 ┣━2-1 本章内容介绍.mp4

 ┣━第3章 深度学习基础组件精讲

 ┣━3-9 本章总结.mp4

 ┣━3-4 激活函数选择.mp4

 ┣━3-6 Normalization 增强模型训练（上）.mp4

 ┣━3-1 本章内容介绍.mp4

 ┣━3-5 优化器选择.mp4

 ┣━3-3 正确的初始化模型参数.mp4

 ┣━3-2 如何划分和处理你的数据集.mp4

 ┣━3-7 Normalization 增强模型训练（下）.mp4

 ┣━3-8 使用正则提升模型表现.mp4

 ┣━第7章 赋予模型认知能力：注意力机制

 ┣━7-12 Multi-head attention（上）.mp4

 ┣━7-2 什么是注意力机制？.mp4

 ┣━7-4 几种典型的注意力机制 hard、soft、local attention.mp4

 ┣━7-14 Pointwise FeedForward.mp4

 ┣━7-16 transformer（上）.mp4

 ┣━7-9 g2p dataset 编写.mp4

 ┣━7-20 inference和attention map展示（上）.mp4

 ┣━7-7 用Transformer实现G2P（上）.mp4

 ┣━7-13 Multi-head attention（下）.mp4

 ┣━7-1 本章内容介绍.mp4

 ┣━7-22 本章总结.mp4

 ┣━7-18 trainer脚本编写.mp4

 ┣━7-10 model结构和位置编码.mp4

 ┣━7-5 自注意力机制：self-attention.mp4

 ┣━7-21 inference和attention map展示（下）.mp4

 ┣━7-17 transformer（下）.mp4

 ┣━7-8 用Transformer实现G2P（下）.mp4

 ┣━7-6 Transformer.mp4

 ┣━7-19 infer推理函数编写.mp4

 ┣━7-15 decoder.mp4

 ┣━7-11 encoder.mp4

 ┣━7-3 注意力机制的一般性原理.mp4

 ┣━第4章 图像处理利器：卷积神经网络

 ┣━4-12 手势识别应用来源和项目分析.mp4

 ┣━4-20 本章总结.mp4

 ┣━4-13 模型设计.mp4

 ┣━4-15 MoocTrialNet模型搭建（2）.mp4

 ┣━4-5 卷积运算是怎样的过程（下）.mp4

 ┣━4-17 MoocTrialNet模型搭建（4）.mp4

 ┣━4-1 本章内容介绍.mp4

 ┣━4-6 用池化进行下采样.mp4

 ┣━4-2 人类视觉和卷积神经网络关系.mp4

 ┣━4-16 MoocTrialNet模型搭建（3）.mp4

 ┣━4-3 卷积神经网络的应用.mp4

 ┣━4-10 Vgg介绍及实现.mp4

 ┣━4-9 利用残差搭建更深的网络.mp4

 ┣━4-11 图片的数据增广.mp4

 ┣━4-19 模型评估和选择.mp4

 ┣━4-14 MoocTrialNet模型搭建（1）.mp4

 ┣━4-8 几种卷积的变体（下）.mp4

 ┣━4-18 MoocTrialNet模型搭建（5）.mp4

 ┣━4-4 卷积运算是怎样的过程（上）.mp4

 ┣━4-7 几种卷积的变体（上）.mp4

 ┣━第1章 初识深度学习

 ┣━1-4 深度学习路线图.mp4

 ┣━1-2 本章内容介绍.mp4

 ┣━1-5 深度学习应用.mp4

 ┣━1-3 神经网络&amp;深度学习.mp4

 ┣━1-1 系统入门深度学习，从这里轻松开始.mp4

 ┣━1-6 本章总结.mp4

 ┣━第9章 深度学习新范式：半监督学习

 ┣━9-1 本章内容介绍.mp4

 ┣━9-10 utils编写（3）.mp4

 ┣━9-14 trainer 编写（1）.mp4

 ┣━9-11 utils编写（4）.mp4

 ┣━9-18 本章总结.mp4

 ┣━9-2 半监督学习是什么？.mp4

 ┣━9-8 utils编写（1）.mp4

 ┣━9-4 几种典型的半监督学习方法（上）.mp4

 ┣━9-13 loss 编写.mp4

 ┣━9-9 utils编写（2）.mp4

 ┣━9-17 trainer 编写（4）.mp4

 ┣━9-5 几种典型的半监督学习方法（下）.mp4

 ┣━9-6 在Cifar10上实现MixMatch半监督学习-论文拆解.mp4

 ┣━9-7 超参和dataset.mp4

 ┣━9-12 model编写.mp4

 ┣━9-3 半监督学习能解决什么问题？.mp4

 ┣━9-15 trainer 编写（2）.mp4

 ┣━9-16 trainer 编写（3）.mp4

  
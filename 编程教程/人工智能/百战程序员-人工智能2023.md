# 百战程序员-人工智能2023

## 联系方式

客服微信号：itziyuan_xiaozhi

<img src="https://ziyuanyun.oss-cn-guangzhou.aliyuncs.com/common/20240614073449/666b82192834a.jpg" width="200" height="200" alt="二维码">

## 课程简介

下载链接：https://it.bcwex.shop/posts?id=631

<img src="https://ziyuanyun.oss-cn-guangzhou.aliyuncs.com/yun/20240515152141/664462859f9b7.jpg" width="500" alt="">

  百战程序员-人工智能2023



 资源截图

 百战程序员-人工智能2023



 资源目录

 ├──1&#8211;人工智能基础-快速入门

 | ├──1&#8211;人工智能就业、薪资、各行业应用

 | | ├──1-人工智能就业前景与薪资.mp4 52.07M

 | | ├──2-人工智能适合人群与必备技能.mp4 44.57M

 | | ├──3-人工智能时代是发展的必然.mp4 23.22M

 | | └──4-人工智能在各领域的应用.mp4 57.73M

 | └──2&#8211;机器学习和深度学习、有监督和无监督

 | | ├──1-人工智能常见流程.mp4 89.62M

 | | ├──2-机器学习不同的学习方式.mp4 83.51M

 | | ├──3-深度学习比传统机器学习有优势.mp4 84.81M

 | | ├──4-有监督机器学习任务与本质.mp4 37.50M

 | | └──5-无监督机器学习任务与本质.mp4 50.15M

 ├──10&#8211;机器学习与大数据-Kaggle竞赛实战

 | ├──1&#8211;药店销量预测案例

 | | ├──1-Rossmann药店销量预测_kaggle的介绍.mp4 36.33M

 | | ├──2-对数据字段的介绍_导包.mp4 19.90M

 | | ├──3-自定义损失函数.mp4 21.12M

 | | ├──4-对数据里面的目标变量sales的一个分析.mp4 44.88M

 | | ├──5-数据的预处理.mp4 111.81M

 | | ├──6-模型的训练_评估.mp4 66.64M

 | | └──7-kaggle竞赛网站学习.mp4 172.16M

 | └──2&#8211;网页分类案例

 | | ├──1-Kaggle网页分类竞赛介绍.mp4 25.08M

 | | ├──10-使用SparkML对网页分类竞赛数据预处理_模型训练_交叉验证调参_02.mp4 85.63M

 | | ├──11-使用SparkML对网页分类竞赛数据预处理_模型训练_交叉验证调参_03.mp4 68.80M

 | | ├──12-使用SparkML对网页分类竞赛数据预处理_模型训练_交叉验证调参_04.mp4 74.74M

 | | ├──2-评估指标ROC和AUC.mp4 56.19M

 | | ├──3-评估指标ROC和AUC.mp4 49.03M

 | | ├──4-竞赛其他相关提交成绩排行榜.mp4 40.19M

 | | ├──5-数据导入.mp4 68.41M

 | | ├──6-MLlib对网页分类竞赛数据预处理.mp4 102.96M

 | | ├──7-MLlib对网页分类竞赛数据预处理_模型训练.mp4 71.27M

 | | ├──8-MLlib对网页分类竞赛模型训练_模型训练评估_搜索最佳超参数.mp4 62.48M

 | | └──9-使用SparkML对网页分类竞赛数据预处理_模型训练_交叉验证调参_01.mp4 87.47M

 ├──11&#8211;机器学习与大数据-海量数据挖掘工具

 | ├──1&#8211;Spark计算框架基础

 | | ├──1-Spark特性_01.mp4 41.68M

 | | ├──10-分布式计算所需进程.mp4 26.30M

 | | ├──11-两种算子操作本质区别.mp4 56.31M

 | | ├──12-Spark算子操作实战讲解_代码实战WordCount_01.mp4 69.39M

 | | ├──13-Spark算子操作实战讲解_代码实战WordCount_02.mp4 56.06M

 | | ├──14-Spark算子操作实战讲解_代码实战WordCount_03.mp4 44.12M

 | | ├──15-Spark算子操作实战讲解_代码实战WordCount_04.mp4 41.91M

 | | ├──2-Spark特性_02.mp4 35.15M

 | | ├──3-Spark对比hadoop优势.mp4 19.34M

 | | ├──4-回顾hadoop讲解shuffle.mp4 35.80M

 | | ├──5-分布式计算框架Shuffle的原理_01.mp4 46.22M

 | | ├──6-分布式计算框架Shuffle的原理_02.mp4 44.94M

 | | ├──7-分布式计算框架Shuffle的原理_03.mp4 29.26M

 | | ├──8-Spark的RDD特性_01.mp4 33.08M

 | | └──9-Spark的RDD特性_02.mp4 33.41M

 | ├──2&#8211;Spark计算框架深入

 | | ├──1-Spark数据缓存机制.mp4 54.43M

 | | ├──10-讲解构建稀疏和稠密向量_01.mp4 80.62M

 | | ├──11-讲解构建稀疏和稠密向量_01.mp4 101.76M

 | | ├──12-构建LabeledPoint.mp4 111.08M

 | | ├──13-介绍SparkMLlib模块中实现的算法和调用.mp4 91.18M

 | | ├──2-Spark宽依赖和窄依赖_01.mp4 39.74M

 | | ├──3-Spark宽依赖和窄依赖_02.mp4 38.86M

 | | ├──4-Spark宽依赖和窄依赖_03.mp4 28.03M

 | | ├──5-Spark术语总结.mp4 89.66M

 | | ├──6-分布式文件系统Block块的大小配置.mp4 114.54M

 | | ├──7-Spark程序启动运行流程详解_01.mp4 49.37M

 | | ├──8-Spark程序启动运行流程详解_02.mp4 71.40M

 | | └──9-Spark程序启动运行流程详解_03.mp4 47.28M

 | └──3&#8211;Spark机器学习MLlib和ML模块

 | | ├──1-SparkMLlib对于逻辑回归算法的调用.mp4 170.37M

 | | ├──10-SparkMLlib调用KMeans聚类_调用决策树(1)_3.mp4 104.55M

 | | ├──11-使用逻辑回归和随机森林对股票Stock预测案例实战_1.mp4 89.72M

 | | ├──12-使用逻辑回归和随机森林对股票Stock预测案例实战_2.mp4 92.22M

 | | ├──13-使用逻辑回归和随机森林对股票Stock预测案例实战_3.mp4 84.20M

 | | ├──14-从数据转化到训练集的构建.mp4 146.40M

 | | ├──15-模型的训练以及评估和调超参_1.mp4 84.62M

 | | ├──16-模型的训练以及评估和调超参_2.mp4 88.90M

 | | ├──17-模型的训练以及评估和调超参_3.mp4 161.69M

 | | ├──18-SparkML机器学习库概念讲解_1.mp4 146.78M

 | | ├──19-SparkML机器学习库概念讲解_2.mp4 121.35M

 | | ├──2-SparkMLlib调用逻辑回归_自定义阈值_1.mp4 120.62M

 | | ├──20-SparkML机器学习库代码实战讲解_1.mp4 146.48M

 | | ├──21-SparkML机器学习库代码实战讲解_2.mp4 169.53M

 | | ├──22-SparkML网页分类案例代码实战续（1）_1.mp4 143.99M

 | | ├──23-SparkML网页分类案例代码实战续（1）_2.mp4 143.95M

 | | ├──24-SparkML网页分类案例代码实战续（2）_1.mp4 177.12M

 | | ├──25-SparkML网页分类案例代码实战续（2）_2.mp4 99.25M

 | | ├──26-SparkML网页分类案例代码实战续（3）.mp4 9.82M

 | | ├──3-SparkMLlib调用逻辑回归_自定义阈值_2.mp4 109.35M

 | | ├──4-SparkMLlib调用逻辑回归_使用标准归一化_1.mp4 105.05M

 | | ├──5-SparkMLlib调用逻辑回归_使用标准归一化_2.mp4 255.32M

 | | ├──6-SparkMLlib调用逻辑回归_使用标准归一化_3.mp4 63.11M

 | | ├──7-SparkMLlib调用逻辑回归_使用标准归一化_4.mp4 140.87M

 | | ├──8-SparkMLlib调用KMeans聚类_调用决策树(1)_1.mp4 80.22M

 | | └──9-SparkMLlib调用KMeans聚类_调用决策树(1)_2.mp4 145.67M

 ├──12&#8211;机器学习与大数据-推荐系统项目实战

 | ├──1&#8211;推荐系统&#8211;流程与架构

 | | ├──1-推荐系统_隐式用户反馈_1.mp4 88.31M

 | | ├──10-推荐系统列表_关联特征权重_基本特征权重的计算_2.mp4 112.85M

 | | ├──11-推荐系统列表_关联特征权重_基本特征权重的计算_3.mp4 103.28M

 | | ├──12-推荐系统_数据源_1.mp4 79.07M

 | | ├──13-推荐系统_数据源_2.mp4 82.90M

 | | ├──2-推荐系统_隐式用户反馈_2.mp4 119.78M

 | | ├──3-推荐系统_协同过滤_1.mp4 60.31M

 | | ├──4-推荐系统_协同过滤_2.mp4 61.36M

 | | ├──5-推荐系统_协同过滤_3.mp4 60.51M

 | | ├──6-推荐系统_协同过滤_4.mp4 56.16M

 | | ├──7-推荐系统架构_实时_离线_1.mp4 100.65M

 | | ├──8-推荐系统架构_实时_离线_2.mp4 104.74M

 | | └──9-推荐系统列表_关联特征权重_基本特征权重的计算_1.mp4 77.80M

 | ├──2&#8211;推荐系统&#8211;数据预处理和模型构建评估实战

 | | ├──1-HQL语句_python脚本构建中间结果_1.mp4 155.76M

 | | ├──10-MLlib调用算法计算模型文件并存储_2.mp4 93.65M

 | | ├──11-MLlib调用算法计算模型文件并存储_3.mp4 107.32M

 | | ├──12-ACC准确率和AUC面积的计算以及意义.mp4 214.40M

 | | ├──2-HQL语句_python脚本构建中间结果_2.mp4 122.28M

 | | ├──3-HQL语句_python脚本构建中间结果_3.mp4 123.74M

 | | ├──4-HQL语句_python脚本构建中间结果_4.mp4 111.87M

 | | ├──5-推荐系统_数据预处理_spark构建特征索引_标签列_1.mp4 116.88M

 | | ├──6-spark构建特征索引_标签列_2.mp4 91.86M

 | | ├──7-spark构建特征索引_标签列_3.mp4 97.86M

 | | ├──8-spark构建特征索引_标签列_4.mp4 98.61M

 | | └──9-MLlib调用算法计算模型文件并存储_1.mp4 99.64M

 | └──3&#8211;推荐系统&#8211;模型使用和推荐服务

 | | ├──1-推荐模型文件使用思路.mp4 61.89M

 | | ├──10-Dubbo推荐服务演示_SparkMLlib介绍_1.mp4 110.16M

 | | ├──11-Dubbo推荐服务演示_SparkMLlib介绍_2.mp4 140.10M

 | | ├──12-Dubbo推荐服务演示_SparkMLlib介绍_3.mp4 157.45M

 | | ├──2-Redis数据库安装及其使用.mp4 47.93M

 | | ├──3-实时在线推荐列表计算逻辑代码讲解_1.mp4 165.06M

 | | ├──4-实时在线推荐列表计算逻辑代码讲解_2.mp4 98.49M

 | | ├──5-实时在线推荐列表计算逻辑代码讲解_3.mp4 90.57M

 | | ├──6-实时在线推荐列表计算逻辑代码讲解_4.mp4 94.68M

 | | ├──7-使用Dubbo将推荐系统做成服务_1.mp4 82.21M

 | | ├──8-使用Dubbo将推荐系统做成服务_2.mp4 103.88M

 | | └──9-使用Dubbo将推荐系统做成服务_3.mp4 119.95M

 ├──13&#8211;深度学习-原理和进阶

 | ├──1&#8211;神经网络算法

 | | ├──1-神经网络是有监督的算法_生物神经元到人工神经元.mp4 94.41M

 | | ├──2-三种常见的激活函数_网络拓扑介绍_优化算法.mp4 53.63M

 | | ├──3-单层神经网络正向传播计算过程_用神经网络理解逻辑回归做多分类.mp4 67.67M

 | | ├──4-用神经网络理解Softmax回归.mp4 67.20M

 | | ├──5-隐藏层的意义_隐藏层相当于去做预处理_升维降维.mp4 117.52M

 | | ├──6-多节点网络输出_sklearn中NN模块的介绍.mp4 90.57M

 | | ├──7-sklearn中NN模型的代码使用.mp4 123.62M

 | | ├──8-隐藏层激活函数必须是非线性的.mp4 21.95M

 | | └──9-tensorflow概要_conda创建虚拟环境_CPU版本的tensorflow安装.mp4 155.50M

 | ├──2&#8211;TensorFlow深度学习工具

 | | ├──1-CUDA下载地址_CUDA显卡白名单地址.mp4 68.65M

 | | ├──2-CUDA安装_cudnn安装_环境变量配置_检验是否安装成功.mp4 74.12M

 | | ├──3-Tensorflow代码运行机制_TF基础的代码.mp4 120.73M

 | | ├──4-TF实现线性回归解析解的方式_TF实现线性回归梯度下降的方式.mp4 173.47M

 | | ├──5-TF实现线性回归BGD的方式_使用Optimizer_每轮打乱数据.mp4 233.26M

 | | ├──6-TF实现Softmax回归来识别MNIST手写数字.mp4 137.04M

 | | └──7-TF实现DNN来识别MNIST手写数字.mp4 132.73M

 | └──3&#8211;反向传播推导_Python代码实现神经网络

 | | ├──1-反向传播_链式求导法则.mp4 86.47M

 | | ├──2-反向传播推导(一).mp4 127.90M

 | | ├──3-反向传播推导(二)从输出层到最后一个隐藏层.mp4 121.37M

 | | ├──4-反向传播推导(三)从输出层到最后一个隐藏层Softmax多分类为例.mp4 81.20M

 | | ├──5-反向传播推导(四)关于Δ和a还有梯度的更新事宜.mp4 34.57M

 | | ├──6-python实现神经网络训练代码讲解(一).mp4 84.17M

 | | └──7-python实现神经网络正向反向传播训练.mp4 112.23M

 ├──14&#8211;深度学习-图像识别原理

 | ├──1&#8211;卷积神经网络原理

 | | ├──1-回顾深度神经网络_卷积层是局部连接.mp4 131.17M

 | | ├──2-单通道卷积的计算.mp4 104.01M

 | | ├──3-彩色图片卷积的计算.mp4 52.79M

 | | ├──4-卷积层权值共享.mp4 63.93M

 | | ├──5-卷积的补充与Padding填充模式.mp4 97.00M

 | | ├──6-卷积的计算TF中的API操作与参数.mp4 93.50M

 | | ├──7-池化的概念和TF中的API的操作与参数.mp4 64.09M

 | | └──8-经典的CNN架构和LeNet5.mp4 137.21M

 | ├──2&#8211;卷积神经网络优化

 | | ├──1-AlexNet网络结构_连续使用小的卷积核好处.mp4 109.38M

 | | ├──10-Optimizer_Adagrad_Adadelta_RMSprop.mp4 121.41M

 | | ├──11-Optimizer_Adam.mp4 141.12M

 | | ├──2-Dropout技术点思想和运用.mp4 113.94M

 | | ├──3-数据增强技术点_CNN对MNIST数据集分类_卷积池化代码.mp4 77.55M

 | | ├──4-CNN对MNIST数据集分类_全连接层以及训练代码.mp4 125.88M

 | | ├──5-深度学习网络对应ACC准确率忽然下降的思考点.mp4 104.08M

 | | ├──6-减轻梯度消失问题中激活函数发挥的作用.mp4 42.02M

 | | ├──7-减轻梯度消失问题中参数初始化发挥的作用.mp4 66.51M

 | | ├──8-VGG网络结构_以及1乘1的卷积核的作用和好处.mp4 123.25M

 | | └──9-Optimizer_SGD_Momentum.mp4 89.70M

 | ├──3&#8211;经典卷积网络算法

 | | ├──1-Keras介绍_以及不同项目调用不同的python环境和CUDA环境.mp4 141.12M

 | | ├──2-VGG16_Fine-tuning_对MNIST做手写数字识别.mp4 116.63M

 | | ├──3-InceptionV1_V2.mp4 165.86M

 | | ├──4-InceptionV3_以及InceptionV3对皮肤癌图片识别.mp4 166.97M

 | | ├──5-ResNet残差单元_BottlenetBlocK.mp4 121.51M

 | | ├──6-DenseNet和Keras里面的实现.mp4 150.61M

 | | ├──7-DenseNet在Keras里面的代码实现.mp4 66.75M

 | | ├──8-BatchNormalization.mp4 99.23M

 | | └──9-Mobilenet网络架构.mp4 150.05M

 | ├──4&#8211;古典目标检测

 | | ├──1-图像识别任务_古典目标检测.mp4 196.48M

 | | ├──2-使用OpenCV调用分类器找到目标框.mp4 98.21M

 | | ├──3-IOU以及python计算的代码.mp4 23.56M

 | | ├──4-R-CNN和SPP-net.mp4 124.06M

 | | └──5-从FastRCNN引入FasterRCNN.mp4 120.81M

 | └──5&#8211;现代目标检测之FasterRCNN

 | | ├──1-回顾RCNN_SPPnet_Fast-RCNN.mp4 121.18M

 | | ├──2-FasterRNN的核心RPN_正向传播的框过滤_NMS.mp4 214.14M

 | | ├──3-NMS代码实现流程_mAP目标检测平均指标.mp4 157.18M

 | | ├──4-FasterRCNN论文讲解_从介绍到RPN的loss.mp4 210.02M

 | | └──5-FasterRCNN论文讲解_从RPN损失到评估指标对比.mp4 247.99M

 ├──15&#8211;深度学习-图像识别项目实战

 | ├──1&#8211;车牌识别

 | | ├──1-基于CascadeClassifier来提取目标框做车牌识别代码详解_01.mp4 83.16M

 | | ├──2-基于CascadeClassifier来提取目标框做车牌识别代码详解_02.mp4 86.40M

 | | ├──3-基于CascadeClassifier来提取目标框做车牌识别代码详解_03.mp4 48.80M

 | | ├──4-基于CascadeClassifier来提取目标框做车牌识别代码详解_04.mp4 73.07M

 | | └──5-车牌识别项目关于目标检测的问题.mp4 39.48M

 | ├──2&#8211;自然场景下的目标检测及源码分析

 | | ├──1-FasterRCNN项目代码_环境说明_数据集详解_项目结构说明.mp4 116.49M

 | | ├──10-FasterRCNN代码_构建head.mp4 67.56M

 | | ├──11-FasterRCNN代码_构建RPN网络_01.mp4 124.40M

 | | ├──12-FasterRCNN代码_构建RPN网络_02.mp4 88.47M

 | | ├──13-FasterRCNN代码_根据RPN网络得到校正后的预测的框_01.mp4 83.97M

 | | ├──14-FasterRCNN代码_根据RPN网络得到校正后的预测的框_02.mp4 119.92M

 | | ├──15-FasterRCNN代码_bbox剪裁_NMS非极大值抑制.mp4 91.40M

 | | ├──16-FasterRCNN代码_给RPN准备正负例样本_01.mp4 100.30M

 | | ├──17-FasterRCNN代码_给RPN准备正负例样本_02.mp4 165.71M

 | | ├──18-FasterRCNN代码_给RPN准备正负例样本_03.mp4 43.58M

 | | ├──19-FasterRCNN代码_给RPN准备正负例样本_04.mp4 46.68M

 | | ├──2-FasterRCNN项目代码_数据加载.mp4 96.17M

 | | ├──20-FasterRCNN代码_给RPN准备正负例样本_05.mp4 78.02M

 | | ├──21-FasterRCNN代码_给RPN准备正负例样本_06.mp4 114.63M

 | | ├──22-FasterRCNN代码_给RPN准备正负例样本_07.mp4 100.02M

 | | ├──23-FasterRCNN代码_给RPN准备正负例样本_08.mp4 57.32M

 | | ├──24-FasterRCNN代码_给最终RCNN准备正负例样本_ROI池化_01.mp4 53.41M

 | | ├──25-FasterRCNN代码_给最终RCNN准备正负例样本_ROI池化_02.mp4 74.40M

 | | ├──26-FasterRCNN代码_添加Loss损失_smoothL1loss.mp4 76.44M

 | | ├──3-FasterRCNN项目代码_数据增强.mp4 71.78M

 | | ├──4-FasterRCNN项目代码_数据初始化.mp4 73.27M

 | | ├──5-FasterRCNN项目代码_模型的训练.mp4 39.33M

 | | ├──6-回归整体训练流程_详解读取数据blob_01.mp4 81.18M

 | | ├──7-回归整体训练流程_详解读取数据blob_02.mp4 75.71M

 | | ├──8-回归整体训练流程_详解读取数据blob_03.mp4 39.22M

 | | └──9-回归整体训练流程_详解读取数据blob_04.mp4 64.48M

 | └──3&#8211;图像风格迁移

 | | ├──1-图片风格融合项目_架构_代码实现要点_1.mp4 81.07M

 | | ├──2-图片风格融合项目_架构_代码实现要点_2.mp4 85.15M

 | | ├──3-图片风格融合项目_架构_代码实现要点_3.mp4 75.40M

 | | └──4-图片风格融合项目_架构_代码实现要点_4.mp4 86.94M

 ├──16&#8211;深度学习-目标检测YOLO(V1-V4全版本)实战

 | ├──1&#8211;YOLOv1详解

 | | ├──1-YOLOv1论文详解_算法特点介绍.mp4 179.69M

 | | ├──2-YOLOv1论文详解_网络架构_思想.mp4 215.92M

 | | ├──3-YOLOv1论文详解_训练中的技巧_Loss损失函数.mp4 253.21M

 | | └──4-YOLOv1论文详解_NMS_局限性.mp4 82.07M

 | ├──2&#8211;YOLOv2详解

 | | ├──1-YOLOv2论文详解_BN_高分辨率_引入AnchorBoxes.mp4 158.76M

 | | ├──2-YOLOv2论文详解_mAP更better的一些点.mp4 257.43M

 | | ├──3-YOLOv2论文详解_Darknet19_分类数据和检测数据集融合_多标签.mp4 141.41M

 | | └──4-YOLOv2论文详解_层级分类_层级分类用于目标检测.mp4 183.51M

 | ├──3&#8211;YOLOv3详解

 | | ├──1-YOLOv3论文详解_每个框都要预测多个类别概率.mp4 86.51M

 | | ├──2-YOLOv3论文详解_引入了FPN的思想特征融合_多路输出_DarkNet53.mp4 158.58M

 | | ├──3-YOLOv3论文详解_总结_FocalLoss.mp4 147.48M

 | | ├──4-YOLOv4论文概述_介绍.mp4 139.49M

 | | └──5-YOLOv4论文概述_BOS_BOF.mp4 297.31M

 | ├──4&#8211;YOLOv3代码实战

 | | ├──1-YOLOv3代码剖析_项目介绍.mp4 157.02M

 | | ├──2-YOLOv3代码剖析_聚类anchors_构建backbone主干网络.mp4 238.06M

 | | ├──3-YOLOv3代码剖析_model输出之后的预测框的计算.mp4 223.57M

 | | ├──4-YOLOv3代码剖析_使用model预测的其余代码.mp4 86.53M

 | | ├──5-YOLOv3代码剖析_weights到h5模型的转换.mp4 144.69M

 | | └──6-YOLOv3代码剖析_模型的训练部分详解.mp4 316.56M

 | └──5&#8211;YOLOv4详解

 | | ├──1-YOLOv4_BOF_DropBlock_FocalLoss.mp4 207.14M

 | | ├──2-YOLOv4_BOF_GIoU_DIoU_CIoU.mp4 90.48M

 | | ├──3-YOLOv4_BOS_ASPP_SAM_SoftNMS_Mish.mp4 216.07M

 | | └──4-YOLOv4_BOS_SAM_PAN_CSP_CmBN.mp4 220.91M

 ├──17&#8211;深度学习-语义分割原理和实战

 | ├──1&#8211;上采样_双线性插值_转置卷积

 | | ├──1-前言.mp4 19.46M

 | | ├──2-上采样_repeat.mp4 23.90M

 | | ├──3-线性插值.mp4 34.48M

 | | ├──4-双线性插值.mp4 125.71M

 | | ├──5-转置卷积_以及TF的API.mp4 114.25M

 | | ├──6-双线性插值作为转置卷积核的初始参数.mp4 145.01M

 | | ├──7-ROI Align.mp4 58.38M

 | | ├──8-FPN思想与网络结构.mp4 92.14M

 | | └──9-FPN应用于FasterRCNN_ResNetFPN.mp4 95.52M

 | ├──2&#8211;医疗图像UNet语义分割

 | | ├──1-语义分割的基本概念.mp4 18.33M

 | | ├──2-FCN全卷积网络做语义分割.mp4 36.54M

 | | ├──3-UNet网络结构.mp4 30.41M

 | | └──4-UNet网络医疗图像的语义分割.mp4 81.21M

 | └──3&#8211;蒙版弹幕MaskRCNN语义分割

 | | ├──1-MaskRCNN网络结构.mp4 106.38M

 | | ├──2-MaskRCNN的项目展示.mp4 250.54M

 | | ├──3-MaskRCNN网络架构回顾.mp4 151.34M

 | | ├──4-MaskRCNN根据文档和论文总结重要的知识点.mp4 239.08M

 | | ├──5-MaskRCNN项目关于运行代码环境的说明.mp4 44.16M

 | | └──6-MaskRCNN源码config和model.mp4 244.48M

 ├──18&#8211;深度学习-人脸识别项目实战

 ├──19&#8211;深度学习-NLP自然语言处理原理和进阶

 | ├──1&#8211;词向量与词嵌入

 | | ├──1-N-gram语言模型.mp4 116.32M

 | | ├──2-NPLM神经网络语言模型.mp4 155.81M

 | | ├──3-词向量的作用.mp4 58.00M

 | | ├──4-CBOW模型思想和计算过程.mp4 196.59M

 | | ├──5-Skip-gram模型思想和计算过程.mp4 44.35M

 | | ├──6-Huffman树_分层Softmax的思想.mp4 113.79M

 | | ├──7-分层Softmax应用到CBOW模型上.mp4 64.28M

 | | └──8-负采样和负采样应用到CBOW模型上.mp4 66.07M

 | ├──2&#8211;循环神经网络原理与优化

 | | ├──1-理解RNN循环神经网络拓扑结构.mp4 122.64M

 | | ├──2-理解RNN循环神经网络计算流程.mp4 55.91M

 | | ├──3-利用RNN循环神经网络对MNIST手写数字识别.mp4 127.75M

 | | ├──4-理解LSTM长短时记忆_记住Topo和公式.mp4 185.30M

 | | ├──5-VanillaRNN的回顾复习.mp4 123.51M

 | | ├──6-补充讲一下为什么RNN中链越长越容易梯度消失.mp4 44.24M

 | | ├──7-LSTM的回顾复习_LSTM手写数字识别.mp4 35.32M

 | | ├──8-双向RNN_LSTM.mp4 52.01M

 | | └──9-RNN里面应用的Topology结构.mp4 23.04M

 | ├──3&#8211;从Attention机制到Transformer

 | | ├──1-Seq2Seq中Attention注意力机制.mp4 87.67M

 | | ├──2-Transformer_Self-Attention_Multi-head.mp4 100.40M

 | | └──3-Transformer_Positional_使用逻辑_网络结构总结.mp4 102.40M

 | └──4&#8211;ELMO_BERT_GPT

 | | ├──1-ELMO.mp4 62.44M

 | | ├──2-BERT理论.mp4 99.73M

 | | └──3-ERNIE_GPT.mp4 56.34M

 ├──2&#8211;人工智能基础-Python基础

 | ├──1&#8211;Python开发环境搭建

 | | ├──1-下载Miniconda运行环境.mp4 100.75M

 | | ├──2-Miniconda安装和测试.mp4 57.12M

 | | ├──3-Pycharm安装和代码运行.mp4 71.57M

 | | ├──4-Jupyter安装和代码运行.mp4 37.10M

 | | ├──5-Jupyter常用快捷键.mp4 32.23M

 | | ├──6-Conda虚拟环境创建与Python模块安装.mp4 73.12M

 | | └──7-关联虚拟环境运行代码.mp4 38.14M

 | └──2&#8211;Python基础语法

 | | ├──1-Python是强类型的动态脚本语言.mp4 44.15M

 | | ├──10-Python_集合操作_列表.mp4 34.71M

 | | ├──11-Python_集合操作_列表的基本操作.mp4 49.44M

 | | ├──12-Python_集合操作_列表的常用方法.mp4 37.35M

 | | ├──13-Python_集合操作_元组.mp4 43.46M

 | | ├──14-Python_集合操作_字典和常见操作.mp4 38.01M

 | | ├──15-Python_集合操作_字典keys方法_enumerate函数.mp4 22.40M

 | | ├──16-Python_os模块_shutil模块.mp4 51.54M

 | | ├──17-Python_打开并读取文件_中文编码问题.mp4 58.82M

 | | ├──18-Python_函数_定义_调用_返回值_注释.mp4 23.77M

 | | ├──19-Python_函数_局部变量_全局变量.mp4 31.20M

 | | ├──2-Python_控制语句_单双分支.mp4 50.66M

 | | ├──20-Python_函数_默认参数_可变参数.mp4 24.47M

 | | ├──21-Python_函数_递归.mp4 23.46M

 | | ├──22-Python_函数式编程_高阶函数.mp4 24.65M

 | | ├──23-Python_函数式编程_map_reduce_filter_匿名函数.mp4 37.86M

 | | ├──24-Python_函数_闭包.mp4 41.61M

 | | ├──25-Python_函数_装饰器.mp4 30.35M

 | | ├──26-Python_类对象_定义与实例化对象.mp4 44.21M

 | | ├──27-Python_类对象_实例属性和方法_类属性和方法.mp4 38.35M

 | | ├──28-Python_类对象_内置方法.mp4 29.17M

 | | ├──29-Python_类对象_运算符重载_私有对象方法_isinstance函数.mp4 38.46M

 | | ├──3-Python_控制语句_多分支_三元条件运算符.mp4 31.02M

 | | ├──30-Python_类对象_面向对象三大特性_类的继承.mp4 24.66M

 | | ├──31-Python_类对象_子类复用父类构造器和方法_方法重写.mp4 32.00M

 | | ├──4-Python_控制语句_while循环.mp4 25.02M

 | | ├──5-Python_控制语句_for循环.mp4 22.82M

 | | ├──6-Python_控制语句_嵌套循环.mp4 36.15M

 | | ├──7-Python_控制语句_break_continue.mp4 25.23M

 | | ├──8-Python_切片操作.mp4 40.20M

 | | └──9-Python_数据类型.mp4 25.38M

 ├──20&#8211;深度学习-NLP自然语言处理项目实战

 | ├──1&#8211;词向量

 | | ├──1-回顾了词向量里面训练的Topology.mp4 121.72M

 | | ├──2-Word2Vec项目代码_加载数据_构建字典.mp4 96.76M

 | | ├──3-Word2Vec项目代码_构建一个个批次数据.mp4 82.29M

 | | ├──4-Word2Vec项目代码_正向传播的Graph构建_NCE损失的计算本质.mp4 102.84M

 | | ├──5-Word2Vec项目代码_评估比较相似度_最后的训练绘图.mp4 83.28M

 | | └──6-Word2Vec项目代码_总结串讲.mp4 22.52M

 | ├──2&#8211;自然语言处理&#8211;情感分析

 | | ├──1-Keras实战RNN以及词嵌入来做情感分析.mp4 71.10M

 | | ├──2-数据预处理_01.mp4 79.65M

 | | ├──3-数据预处理_02.mp4 45.68M

 | | ├──4-代码讲解_01.mp4 52.29M

 | | ├──5-代码讲解_02.mp4 60.85M

 | | ├──6-代码讲解_03.mp4 53.89M

 | | ├──7-代码讲解_04.mp4 57.19M

 | | └──8-代码讲解_05.mp4 35.88M

 | ├──3&#8211;AI写唐诗

 | | ├──1-AI写唐诗_数据的读取_字典的构建_文本的索引化.mp4 114.96M

 | | ├──2-AI写唐诗_训练数据的构建.mp4 69.75M

 | | ├──3-MultiRNNCell单元.mp4 38.93M

 | | ├──4-AI写唐诗_从词嵌入到构建RNN再到输出层概率输出.mp4 67.03M

 | | ├──5-AI写唐诗_损失的计算_梯度的求解截断和更新_最终的训练代码.mp4 61.73M

 | | └──6-AI写唐诗_模型的使用_增加随机性.mp4 93.87M

 | ├──4&#8211;Seq2Seq聊天机器人

 | | ├──1-从AI写唐诗到Seq2Seq再到Encoder-Decoder.mp4 118.79M

 | | ├──2-Seq2Seq版Chatbot的数据预处理.mp4 93.85M

 | | └──3-Seq2Seq版Chatbot训练和模型使用.mp4 133.29M

 | ├──5&#8211;实战NER命名实体识别项目

 | | ├──1-回顾了一下CRF训练和使用过程.mp4 73.72M

 | | ├──2-介绍了代码目录结构.mp4 23.44M

 | | ├──3-NER代码读取数据和预处理.mp4 97.61M

 | | ├──4-feature进入BiLSTM进行正向传播的过程.mp4 70.91M

 | | ├──5-通过CRF层来计算Loss损失以及训练.mp4 80.51M

 | | ├──6-BiLSTM-CRF模型的预测代码.mp4 64.10M

 | | ├──7-CRF中的特征函数们.mp4 125.97M

 | | ├──8-对比逻辑回归_相比HMM优势.mp4 143.56M

 | | └──9-补充标注偏置问题_HMM做分词代码结构.mp4 141.43M

 | ├──6&#8211;BERT新浪新闻10分类项目

 | | └──1-BERT新浪新闻10分类项目.mp4 104.54M

 | └──7&#8211;GPT2聊天机器人

 | | └──1-GPT2闲聊机器人.mp4 62.28M

 ├──21&#8211;深度学习-OCR文本识别

 ├──22 Pytorch项目实战

 | ├──1&#8211;PyTorch运行环境安装_运行环境测试

 | | ├──1-PyTorch概述.mp4 29.29M

 | | ├──2-PyTorch的安装.mp4 76.45M

 | | ├──3-Pycharm关联PyTorch运行环境.mp4 37.96M

 | | └──4-Jupyter关联PyTorch运行环境.mp4 31.22M

 | ├──2&#8211;PyTorch基础_Tensor张量运算

 | | ├──1-Tensor的创建.mp4 55.14M

 | | ├──2-修改Tensor的形状_索引操作.mp4 76.51M

 | | ├──3-广播机制_逐元素操作.mp4 44.46M

 | | └──4-归并操作_比较操作_矩阵操作.mp4 59.39M

 | ├──3&#8211;PyTorch卷积神经网络_实战CIFAR10

 | | ├──1-PyTorch实战CIFAR10数据_读取和展示.mp4 83.93M

 | | ├──10-PyTorch代码实战加入数据增强.mp4 34.15M

 | | ├──2-PyTorch实战CIFAR10_构建网络_打印网络层次.mp4 58.61M

 | | ├──3-PyTorch实战CIFAR10_训练模型_测试模型.mp4 51.47M

 | | ├──4-PyTorch实战CIFAR10_分类别打印模型准确率.mp4 30.60M

 | | ├──5-使用全局平均池化_使用LeNet模型.mp4 40.97M

 | | ├──6-使用集成学习思想训练识别模型.mp4 86.96M

 | | ├──7-使用VGG16模型提供准确率.mp4 52.90M

 | | ├──8-torchvision里面的预训练模型.mp4 29.84M

 | | └──9-迁移学习_PyTorch代码实战冻结预训练模型参数.mp4 67.71M

 | ├──4&#8211;PyTorch循环神经网络_词性标注

 | | ├──1-PyTorch词性标注_构建数据和词索引号.mp4 28.07M

 | | ├──2-PyTorch词性标注_构建词嵌入层LSTM层和词性输出层.mp4 47.01M

 | | ├──3-PyTorch词性标注_构建数据索引化和训练模型代码.mp4 44.59M

 | | └──4-PyTorch词性标注_测试模型效果.mp4 11.67M

 | └──5&#8211;PyTorch编码器解码器_机器翻译

 | | ├──1-PyTorch中英文翻译_规范化语料库_构建中英文词典索引.mp4 50.41M

 | | ├──2-PyTorch中英文翻译_数据预处理.mp4 42.68M

 | | ├──3-PyTorch中英文翻译_索引化数据_转化成Tensor张量_构建Encoder编码器.mp4 57.69M

 | | ├──4-PyTorch中英文翻译_构建训练函数之Encoder计算.mp4 50.92M

 | | ├──5-PyTorch中英文翻译_构建带Attention注意力机制的Decoder解码器.mp4 79.33M

 | | ├──6-PyTorch中英文翻译_构建训练函数之Decoder计算.mp4 59.08M

 | | ├──7-PyTorch中英文翻译_评估模型函数.mp4 56.52M

 | | └──8-PyTorch中英文翻译_绘制Attentions注意力权重.mp4 33.74M

 ├──23 百度飞桨PaddlePaddle实战【新增】

 | ├──1&#8211;PaddlePaddle框架安装_波士顿房价预测

 | | ├──1-安装PaddlePaddle.mp4 87.34M

 | | ├──2-Pycharm运行出现mkl-service或DLL找不到的问题.mp4 45.21M

 | | ├──3-PaddlePaddle求解线性模型.mp4 50.63M

 | | ├──4-预测波士顿房价_数据读取_正向传播.mp4 60.49M

 | | └──5-预测波士顿房价_反向传播_模型保存_模型测试.mp4 43.72M

 | ├──2&#8211;PaddlePaddle卷积网络_病理性近视识别

 | | ├──1-预测病理性近视_图片数据读取.mp4 97.18M

 | | ├──2-预测病理性近视_模型训练.mp4 86.66M

 | | ├──3-预测病理性近视_定义模型结构_评估模型.mp4 84.10M

 | | └──4-预测病理性近视_调用经典卷积神经网络.mp4 91.83M

 | ├──3&#8211;PaddleDetection工具_PCB电路板缺陷检测

 | | ├──1-PaddleDetection_项目配置.mp4 82.88M

 | | ├──2-安装配置VisualStudio_解决安装模块pycocotools或cython_bbox编译报错问题.mp4 65.48M

 | | ├──3-PCB电路板缺陷检测_Images和Annotations.mp4 83.10M

 | | ├──4-PCB电路板缺陷检测_前期数据的分析.mp4 133.78M

 | | ├──5-PCB电路板缺陷检测_项目配置文件.mp4 42.77M

 | | ├──6-PCB电路板缺陷检测_模型训练.mp4 64.62M

 | | └──7-PCB电路板缺陷检测_模型预测.mp4 51.73M

 | ├──4&#8211;PaddleOCR工具_车牌识别（目标检测+CRNN+CTCLoss)

 | | ├──1-PaddleOCR_项目配置_CCPD数据集介绍.mp4 69.65M

 | | ├──2-车牌识别项目_详解数据准备阶段代码.mp4 42.93M

 | | ├──3-车牌识别项目_运行保存标签和剪切出的车牌图片.mp4 57.48M

 | | ├──4-车牌识别项目_车牌目标框检测模型训练.mp4 61.62M

 | | ├──5-车牌识别项目_车牌字符识别模型训练.mp4 61.89M

 | | └──6-车牌识别项目_车牌识别模型导出及预测.mp4 75.61M

 | ├──5&#8211;PaddleNLP模块_物流信息提取（BiGRU+CRF）

 | | ├──1-PaddleNLP_项目配置.mp4 49.37M

 | | ├──2-PaddleNLP_物流信息提取项目介绍.mp4 48.01M

 | | ├──3-物流信息提取项目_解决导包显示找不到nul问题.mp4 106.19M

 | | ├──4-PaddleNLP_物流信息提取项目_加载数据构建DataSet.mp4 55.51M

 | | ├──5-PaddleNLP_物流信息提取项目_进一步通过DataSet构建出DataLoader.mp4 51.88M

 | | ├──6-PaddleNLP_物流信息提取项目_构建网络模型.mp4 48.53M

 | | ├──7-PaddleNLP_物流信息提取项目_模型训练.mp4 47.34M

 | | └──8-PaddleNLP_物流信息提取项目_合并结果并展示_使用预训练的词向量提升效果.mp4 80.58M

 | └──6&#8211;PaddleNLP模块_物流信息提取（ERNIE版）

 | | ├──1-PaddleNLP_物流信息提取项目_ERNIE实战_加载数据集构建Dataset.mp4 49.47M

 | | ├──2-PaddleNLP_物流信息提取项目_ERNIE实战_详解Tokenizer作用.mp4 57.44M

 | | ├──3-PaddleNLP_物流信息提取项目_ERNIE实战_讲解模型训练和评估代码.mp4 47.78M

 | | └──4-PaddleNLP_物流信息提取项目_ERNIE实战_讲解ChunkEvaluator和输出预测结果.mp4 57.88M

 ├──24 Linux 环境编程基础

 | └──1&#8211;Linux

 | | ├──1-Linux_课程介绍.mp4 3.72M

 | | ├──10-Linux_常用命令_clear、touch、cat命令.mp4 10.13M

 | | ├──11-Linux_常用命令more、head、tail命令.mp4 16.32M

 | | ├──12-Linux_常用命令_mkdir命令.mp4 10.57M

 | | ├──13-Linux_常用命令_cp命令.mp4 16.08M

 | | ├──14-Linux_常用命令_rm、mv命令.mp4 31.83M

 | | ├──15-Linux_常用命令_vi、vim.mp4 30.63M

 | | ├──16-Linux_常用命令_reboot、halt.mp4 4.75M

 | | ├──17-Linux_常用配置_设置时区.mp4 28.84M

 | | ├──18-Linux_常用配置_启动网络.mp4 15.64M

 | | ├──19-Linux_常用配置_修改网段.mp4 12.83M

 | | ├──2-Linux_Linux简介.mp4 17.59M

 | | ├──20-Linux_常用配置_设置网络类型.mp4 25.66M

 | | ├──21-Linux_常用配置_快照与克隆.mp4 16.47M

 | | ├──22-Linux_Xshell的安装与使用.mp4 19.51M

 | | ├──23-Linux_上传与下载_Xftp的使用.mp4 20.33M

 | | ├──24-Linux_上传与下载_lrzsz工具.mp4 43.32M

 | | ├──25-Linux_文件的压缩与解压缩处理.mp4 43.12M

 | | ├──26-Linux_安装MySQL.mp4 79.02M

 | | ├──3-Linux_VMWare安装及使用.mp4 20.92M

 | | ├──4-Linux_安装Linux.mp4 41.97M

 | | ├──5-Linux_目录介绍.mp4 20.31M

 | | ├──6-Linux_Linux中的路径.mp4 18.65M

 | | ├──7-Linux_常用命令_pwd命令.mp4 5.79M

 | | ├──8-Linux_常用命令_cd命令.mp4 8.15M

 | | └──9-Linux_常用命令_ls与ll命令.mp4 34.39M

 ├──25 算法与数据结构

 | └──1&#8211;算法与数据结构

 | | ├──1-数据结构与算法简介.mp4 35.68M

 | | ├──10-哈希表的基本结构.mp4 54.34M

 | | ├──11-哈希表冲突问题.mp4 75.92M

 | | ├──12-哈希表冲突问题2.mp4 72.30M

 | | ├──13-哈希扩容.mp4 111.03M

 | | ├──14-递归与栈.mp4 50.77M

 | | ├──15-线性查找.mp4 57.80M

 | | ├──16-二分查找.mp4 52.32M

 | | ├──17-冒泡排序.mp4 53.19M

 | | ├──18-选择排序.mp4 43.29M

 | | ├──19-插入排序.mp4 31.39M

 | | ├──2-大O表示法.mp4 25.59M

 | | ├──20-归并排序.mp4 84.48M

 | | ├──21-快速排序.mp4 36.63M

 | | ├──22-树结构.mp4 96.85M

 | | ├──23-树结构的遍历.mp4 61.05M

 | | ├──24-最大堆的增加操作.mp4 45.43M

 | | ├──25-最大堆的删除操作.mp4 45.63M

 | | ├──26-二叉树的查找.mp4 100.24M

 | | ├──27-二叉树获取最小值.mp4 25.21M

 | | ├──28-二叉树的添加.mp4 72.66M

 | | ├──29-二叉树的删除.mp4 120.06M

 | | ├──3-线性结构.mp4 53.14M

 | | ├──4-单线链表1.mp4 68.36M

 | | ├──5-单链表2.mp4 221.69M

 | | ├──6-双链表.mp4 103.57M

 | | ├──7-队列(链式).mp4 74.12M

 | | ├──8-队列(线式).mp4 30.99M

 | | └──9-栈与双端队列.mp4 28.12M

 ├──26 强化学习【新增】

 | ├──1&#8211;Q-Learning与SARSA算法

 | | ├──1-强化学习通过智能体与环境交互进行学习.mp4 81.83M

 | | ├──10-代码实战Q-Learning智能体训练模型.mp4 40.30M

 | | ├──11-代码实战Sarsa_Agent和Env整体交互.mp4 45.38M

 | | ├──12-代码实战Sarsa_Agent选择行为和训练模型.mp4 42.69M

 | | ├──13-代码实战SarsaLambda_训练模型.mp4 42.49M

 | | ├──2-引入马尔科夫链和价值评估的Q值与V值.mp4 59.84M

 | | ├──3-详解Q值和V值以及它们之间关系.mp4 82.69M

 | | ├──4-蒙特卡洛采样回溯计算V值.mp4 74.25M

 | | ├──5-蒙特卡洛和时序差分估算状态V值.mp4 82.14M

 | | ├──6-SARSA算法和Q-learning算法.mp4 76.34M

 | | ├──7-理解Q-table_创建maze交互环境.mp4 78.55M

 | | ├──8-代码实战Q-Learning_Agent和Env整体交互.mp4 34.23M

 | | └──9-代码实战Q-Learning智能体选择行为.mp4 38.39M

 | ├──2&#8211;Deep Q-Learning Network

 | | ├──1-DQN算法思想.mp4 59.24M

 | | ├──10-DoubleDQN缓解over-estimate.mp4 44.14M

 | | ├──11-DoubleDQN代码实战.mp4 44.49M

 | | ├──12-DuelingDQN.mp4 88.12M

 | | ├──13-困难样本挖掘_Multi-step_NoiseyNet系统的探索.mp4 91.00M

 | | ├──14-计算Action的方差避免风险.mp4 54.23M

 | | ├──15-Rainbow_DQN如何计算连续型的Actions.mp4 65.35M

 | | ├──2-DQN算法具体流程.mp4 56.17M

 | | ├──3-ε-greedy_ReplayBuffer_FixedQ-targets.mp4 96.70M

 | | ├──4-代码实战DQN_Agent和Env整体交互.mp4 52.25M

 | | ├──5-代码实战DQN_构建Q网络.mp4 70.52M

 | | ├──6-代码实战DQN_定义损失函数_构建Target网络更新逻辑.mp4 85.79M

 | | ├──7-代码实战DQN_训练阶段得到Q网络的预测值和真实值.mp4 53.49M

 | | ├──8-代码实战DQN_训练阶段最小化损失_记录loss方便展示_随着learn的越多选择action随机性减小.mp4 58.93M

 | | └──9-DQN会over-estimate的本质原因.mp4 44.92M

 | ├──3&#8211;Policy Gradient 策略梯度

 | | ├──1-策略梯度PG_对比基于值和基于策略网络的区别.mp4 68.21M

 | | ├──10-策略梯度PG_同一个回合中不同的action回溯不同的TotalReward_代码实战.mp4 34.22M

 | | ├──2-策略梯度PG_明确目标函数和导函数.mp4 62.20M

 | | ├──3-策略梯度PG_简化导函数的公式推导.mp4 36.66M

 | | ├──4-策略梯度PG_总结整体流程_对比交叉熵损失函数求导.mp4 33.38M

 | | ├──5-策略梯度PG_讲解CartPole环境.mp4 55.59M

 | | ├──6-代码实战_策略梯度PG和CartPole交互.mp4 75.57M

 | | ├──7-代码实战_策略梯度PG网络构建.mp4 48.86M

 | | ├──8-代码实战_策略梯度PG选择行为和参数训练.mp4 54.67M

 | | └──9-策略梯度PG_对TotalReward进行均值归一化.mp4 33.07M

 | ├──4&#8211;Actor Critic (A3C)

 | | ├──1-ActorCritic原理_把PG和QLearning结合起来.mp4 55.33M

 | | ├──10-代码实战_A3C_增加actor探索性用到熵_定义worker正太分布抽样和求梯度的逻辑.mp4 36.14M

 | | ├──11-代码实战_A3C_定义AC网络结构_定义worker拉取参数和更新全局网络参数的逻辑.mp4 40.24M

 | | ├──12-代码实战_A3C_结合流程图分三点总结前面讲的代码.mp4 39.73M

 | | ├──13-代码实战_A3C_讲解线程中worker和环境交互.mp4 51.55M

 | | ├──14-代码实战_A3C_讲解线程中worker和GlobalNet交互_代码运行效果展示.mp4 47.18M

 | | ├──2-AdvantageActorCritic_共享参数和修改reward技巧.mp4 86.42M

 | | ├──3-代码实战_ActorCritic与环境交互.mp4 82.51M

 | | ├──4-代码实战_Actor网络构建及训练.mp4 58.07M

 | | ├──5-代码实战_详解Critic网络构建及训练.mp4 87.92M

 | | ├──6-A3C架构和训练流程.mp4 74.66M

 | | ├──7-Pendulum环境_根据网络预测的μ和σ得到连续型的action值.mp4 77.58M

 | | ├──8-代码实战_A3C_讲解Coordinator调度多线程运算.mp4 32.03M

 | | └──9-代码实战_A3C_定义Worker计算loss的逻辑_针对连续型的action提高actor探索性.mp4 36.62M

 | └──5&#8211;DDPG、PPO、DPPO算法

 | | ├──1-DDPG解决DQN不能输出连续型动作的问题_DDPG如何训练Actor和Critic.mp4 81.92M

 | | ├──10-代码实战_PPO与环境整体交互_Actor与Critic网络构建.mp4 32.54M

 | | ├──11-代码实战_定义PPO1和PPO2不同版本Actor的Loss计算逻辑.mp4 41.02M

 | | ├──12-代码实战_剖析PPO代码中如何体现Off-Policy的学习方式_效果展示.mp4 42.12M

 | | ├──13-DPPO分布式PPO.mp4 63.81M

 | | ├──14-代码实战_DPPO_创建一个PPO和多个Worker_创建多线程.mp4 37.79M

 | | ├──15-代码实战_DPPO_GlobalPPO和Workers交替执行.mp4 54.72M

 | | ├──2-代码实战_DDPG_构建Actor和Critic四个网络_定义Critic求loss和求梯度的逻辑.mp4 51.45M

 | | ├──3-代码实战_DDPG_Critic网络构建_Actor网络链式求导.mp4 57.06M

 | | ├──4-代码实战_DDPG_与环境之间的互动_AC训练调整参数_效果展示.mp4 44.17M

 | | ├──5-TD3_使用DoubleNetwork优化DDPG.mp4 63.92M

 | | ├──6-PPO_强调AC如何输出连续型动作_区分On-Policy与Off-Policy.mp4 38.45M

 | | ├──7-PPO_通过重要性采样使得PPO可以做Off-Policy学习.mp4 35.49M

 | | ├──8-PPO_重要性采样的问题_期望矫正但是方差还是不同带来的问题.mp4 38.09M

 | | └──9-PPO_PPO1、TRPO、PPO2三种不同的方式解决两个分布不同的问题.mp4 61.79M

 ├──3&#8211;人工智能基础-Python科学计算和可视化

 | ├──1&#8211;科学计算模型Numpy

 | | ├──1-Numpy_概述_安装_创建数组_获取shape形状.mp4 39.89M

 | | ├──2-Numpy_array_arange.mp4 35.45M

 | | ├──3-Numpy_random随机数生成.mp4 50.54M

 | | ├──4-Numpy_ndarray属性_zeros_ones_like等创建数组函数.mp4 45.37M

 | | ├──5-NumPy_reshape_切片操作_copy函数.mp4 34.47M

 | | ├──6-Numpy_改变数组维度_数组的拼接.mp4 46.50M

 | | ├──7-Numpy_数组的切分和转置.mp4 28.34M

 | | ├──8-Numpy_算术运算_向上向下取整.mp4 34.59M

 | | └──9-Numpy_聚合函数.mp4 23.68M

 | ├──2&#8211;数据可视化模块

 | | ├──1-Matplotlib_概述_绘制直线图.mp4 40.79M

 | | ├──2-Matplotlib_绘制正余弦曲线_散点图_添加图例.mp4 37.73M

 | | ├──3-Matplotlib_绘制柱状图_画布切分多个子画布_柱状图对比.mp4 52.15M

 | | ├──4-Matplotlib_绘制饼图_直方图_同时绘制多组数据分布.mp4 29.54M

 | | └──5-Matplotlib_绘制等高线图_绘制三维图像.mp4 34.90M

 | └──3&#8211;数据处理分析模块Pandas

 | | ├──1-Python_Pandas_Series对象创建.mp4 33.35M

 | | ├──2-Python_Pandas_DataFrame对象创建.mp4 37.19M

 | | ├──3-Python_Pandas_获取Series对象的值.mp4 22.41M

 | | ├──4-Python_Pandas_获取DataFrame对象的值.mp4 28.31M

 | | ├──5-Python_Pandas_条件过滤.mp4 24.66M

 | | ├──6-Python_Pandas_空值的删除与填充.mp4 46.66M

 | | └──7-Python_Pandas_拼接和合并.mp4 44.84M

 ├──4&#8211;人工智能基础-高等数学知识强化

 | ├──1&#8211;数学内容概述

 | | ├──1-人工智能学习数学的必要性_微积分知识点.mp4 28.76M

 | | ├──2-线性代数_概率论知识点.mp4 26.81M

 | | └──3-最优化知识_数学内容学习重点.mp4 40.43M

 | ├──2&#8211;一元函数微分学

 | | ├──1-导数的定义_左导数和右导数.mp4 28.39M

 | | ├──2-导数的几何意义和物理意义.mp4 14.49M

 | | ├──3-常见函数的求导公式.mp4 22.76M

 | | ├──4-导数求解的四则运算法则.mp4 26.52M

 | | ├──5-复合函数求导法则.mp4 19.68M

 | | ├──6-推导激活函数的导函数.mp4 33.40M

 | | ├──7-高阶导数_导数判断单调性_导数与极值.mp4 21.95M

 | | └──8-导数判断凹凸性_导数用于泰勒展开.mp4 44.22M

 | ├──3&#8211;线性代数基础

 | | ├──1-向量的意义_n维欧式空间空间.mp4 20.82M

 | | ├──10-矩阵的逆矩阵.mp4 38.54M

 | | ├──11-矩阵的行列式.mp4 20.13M

 | | ├──2-行向量列向量_转置_数乘_加减乘除.mp4 19.28M

 | | ├──3-向量的内积_向量运算法则.mp4 19.78M

 | | ├──4-学习向量计算的用途举例.mp4 20.32M

 | | ├──5-向量的范数_范数与正则项的关系.mp4 32.40M

 | | ├──6-特殊的向量.mp4 26.45M

 | | ├──7-矩阵_方阵_对称阵_单位阵_对角阵.mp4 18.06M

 | | ├──8-矩阵的运算_加减法_转置.mp4 22.76M

 | | └──9-矩阵相乘.mp4 20.02M

 | ├──4&#8211;多元函数微分学

 | | ├──1-多元函数求偏导.mp4 22.61M

 | | ├──2-高阶偏导数_梯度.mp4 27.15M

 | | ├──3-雅可比矩阵_在神经网络中应用.mp4 37.65M

 | | └──4-Hessian矩阵.mp4 32.93M

 | ├──5&#8211;线性代数高级

 | | ├──1-二次型.mp4 27.70M

 | | ├──10-SVD用于PCA降维.mp4 24.90M

 | | ├──11-SVD用于协同过滤_求逆矩阵.mp4 35.85M

 | | ├──2-补充关于正定负定的理解.mp4 23.48M

 | | ├──3-特征值和特征向量(1).mp4 29.83M

 | | ├──4-特征值和特征向量(2).mp4 30.07M

 | | ├──5-特征值分解.mp4 38.68M

 | | ├──6-多元函数的泰勒展开_矩阵和向量的求导.mp4 44.77M

 | | ├──7-奇异值分解定义.mp4 22.58M

 | | ├──8-求解奇异值分解中的UΣV矩阵.mp4 49.47M

 | | └──9-奇异值分解性质_数据压缩.mp4 38.70M

 | ├──6&#8211;概率论

 | | ├──1-概率论_随机事件与随机事件概率.mp4 21.71M

 | | ├──2-条件概率_贝叶斯公式.mp4 32.64M

 | | ├──3-随机变量.mp4 22.57M

 | | ├──4-数学期望和方差.mp4 22.96M

 | | ├──5-常用随机变量服从的分布.mp4 22.48M

 | | ├──6-随机向量_独立性_协方差_随机向量的正太分布.mp4 32.48M

 | | └──7-最大似然估计思想.mp4 23.42M

 | └──7&#8211;最优化

 | | ├──1-最优化的基本概念.mp4 35.14M

 | | ├──10-拉格朗日函数.mp4 27.46M

 | | ├──2-迭代求解的原因.mp4 20.15M

 | | ├──3-梯度下降法思路.mp4 26.33M

 | | ├──4-梯度下降法的推导.mp4 43.56M

 | | ├──5-牛顿法公式推导以及优缺点.mp4 45.83M

 | | ├──6-坐标下降法_数值优化面临的问题.mp4 23.90M

 | | ├──7-凸集.mp4 21.90M

 | | ├──8-凸函数.mp4 16.93M

 | | └──9-凸优化的性质_一般表达形式.mp4 20.81M

 ├──5&#8211;机器学习-线性回归

 | ├──1&#8211;多元线性回归

 | | ├──1-理解简单线性回归.mp4 51.11M

 | | ├──10-对数似然函数_推导出损失函数MSE.mp4 41.92M

 | | ├──11-把目标函数按照线性代数的方式去表达.mp4 27.00M

 | | ├──12-推导出目标函数的导函数形式.mp4 46.38M

 | | ├──13-θ解析解的公式_是否要考虑损失函数是凸函数.mp4 59.19M

 | | ├──14-Python开发环境版本的选择及下载.mp4 54.07M

 | | ├──15-Anaconda环境安装_Pycharm环境安装.mp4 61.07M

 | | ├──16-Pycharm创建脚本并测试python开发环境.mp4 40.51M

 | | ├──17-解析解的方式求解多元线性回归_数据Xy.mp4 40.41M

 | | ├──18-解析解的方式求解多元线性回归_求解模型_使用模型_绘制图形.mp4 48.31M

 | | ├──19-解析解的方式求解多元线性回归_扩展随机种子概念_增加维度代码的变换.mp4 34.67M

 | | ├──2-最优解_损失函数_MSE.mp4 39.58M

 | | ├──20-Scikit-learn模块的介绍.mp4 29.18M

 | | ├──21-调用Scikit-learn中的多元线性回归求解模型(上).mp4 25.20M

 | | ├──22-调用Scikit-learn中的多元线性回归求解模型(下).mp4 41.02M

 | | ├──3-扩展到多元线性回归.mp4 32.15M

 | | ├──4-理解多元线性回归表达式几种写法的原因.mp4 33.97M

 | | ├──5-理解维度这个概念.mp4 41.41M

 | | ├──6-理解回归一词_中心极限定理_正太分布和做预测.mp4 65.82M

 | | ├──7-假设误差服从正太分布_最大似然估计MLE.mp4 43.11M

 | | ├──8-引入正太分布的概率密度函数.mp4 26.54M

 | | └──9-明确目标通过最大总似然求解θ.mp4 25.83M

 | ├──2&#8211;梯度下降法

 | | ├──1-梯度下降法产生的目的和原因以及思想.mp4 59.45M

 | | ├──10-代码实现全量梯度下降第1步和第2步.mp4 25.70M

 | | ├──11-代码实现全量梯度下降第3步和第4步.mp4 30.73M

 | | ├──12-代码实现随机梯度下降.mp4 26.67M

 | | ├──13-代码实现小批量梯度下降.mp4 27.32M

 | | ├──14-代码改进保证训练数据全都能被随机取到.mp4 40.28M

 | | ├──15-代码改进实现随着迭代增加动态调整学习率.mp4 39.24M

 | | ├──2-梯度下降法公式.mp4 57.12M

 | | ├──3-学习率设置的学问_全局最优解.mp4 56.52M

 | | ├──4-梯度下降法迭代流程总结.mp4 30.28M

 | | ├──5-多元线性回归下的梯度下降法.mp4 43.27M

 | | ├──6-全量梯度下降.mp4 62.84M

 | | ├──7-随机梯度下降_小批量梯度下降.mp4 47.62M

 | | ├──8-对应梯度下降法的问题和挑战.mp4 47.07M

 | | └──9-轮次和批次.mp4 45.22M

 | ├──3&#8211;归一化

 | | ├──1-归一化的目的_维度之间数量级不同产生的矛盾.mp4 63.62M

 | | ├──2-归一化的目的_举例子来理解做归一化和不做归一化的区别.mp4 34.11M

 | | ├──3-归一化的副产品_有可能会提高模型的精度.mp4 21.61M

 | | ├──4-最大值最小值归一化.mp4 24.87M

 | | ├──5-标准归一化.mp4 51.86M

 | | └──6-代码完成标准归一化.mp4 41.13M

 | ├──4&#8211;正则化

 | | ├──1-正则化的目的防止过拟合.mp4 30.71M

 | | ├──2-正则化通过损失函数加入惩罚项使得W越小越好.mp4 35.27M

 | | ├──3-常用的L1和L2正则项以及数学意义.mp4 41.55M

 | | ├──4-L1稀疏性和L2平滑性.mp4 51.64M

 | | └──5-通过L1和L2的导函数理解区别的本质原因.mp4 55.58M

 | └──5&#8211;Lasso回归_Ridge回归_多项式回归

 | | ├──1-代码调用Ridge岭回归.mp4 76.32M

 | | ├──10-实战保险花销预测_特征选择思路.mp4 40.29M

 | | ├──11-实战保险花销预测_特征工程.mp4 17.96M

 | | ├──12-实战保险花销预测_模型训练和评估.mp4 58.86M

 | | ├──2-代码调用Lasso回归.mp4 28.73M

 | | ├──3-代码调用ElasticNet回归.mp4 53.67M

 | | ├──4-升维的意义_多项式回归.mp4 48.06M

 | | ├──5-多项式升维代码实战_传入不同超参数对比.mp4 44.78M

 | | ├──6-多项式升维代码实战_训练模型和评估.mp4 35.06M

 | | ├──7-实战保险花销预测_数据介绍和加载数据.mp4 35.25M

 | | ├──8-实战保险花销预测_数据预处理.mp4 41.38M

 | | └──9-实战保险花销预测_模型训练和评估_选择非线性算法改进.mp4 84.12M

 ├──6&#8211;机器学习-线性分类

 | ├──1&#8211;逻辑回归

 | | ├──1-逻辑回归_Sigmoid函数.mp4 21.14M

 | | ├──10-绘制逻辑回归损失函数_探索两个参数和损失函数变换关系.mp4 39.83M

 | | ├──11-绘制逻辑回归损失函数_绘制3D的图形_分析X1X2两个维度的重要度.mp4 43.87M

 | | ├──12-对逻辑回归函数进行求导_结论在后面会用到.mp4 20.50M

 | | ├──13-对逻辑回归的损失函数求导_推导出导函数的形式.mp4 42.50M

 | | ├──14-实战逻辑回归对鸢尾花数据集进行二分类.mp4 46.63M

 | | ├──15-OneVsRest将多分类问题转化成多个二分类问题.mp4 26.13M

 | | ├──16-实战逻辑回归对鸢尾花数据集进行多分类.mp4 40.46M

 | | ├──2-sigmoid函数作用.mp4 38.15M

 | | ├──3-逻辑回归为什么用sigmoid函数_预备知识.mp4 31.00M

 | | ├──4-证明伯努利分布是指数族分布_推导出逻辑回归公式.mp4 41.97M

 | | ├──5-回想多元线性回归公式其实也是从广义线性回归推导出来的.mp4 6.71M

 | | ├──6-推导逻辑回归损失函数_得到总似然的公式.mp4 29.61M

 | | ├──7-推导逻辑回归损失函数_得到最终形式.mp4 12.43M

 | | ├──8-绘制逻辑回归损失函数_读入数据计算最优解模型_实现逻辑回归预测_实现逻辑回归损失函数.mp4 56.56M

 | | └──9-绘制逻辑回归损失函数_探索单个参数和损失的关系.mp4 30.72M

 | ├──2&#8211;Softmax回归

 | | ├──1-证明多项式分布属于指数族分布一种.mp4 27.93M

 | | ├──10-实战音乐分类器_代码使用傅里叶变换将混音文件进行投影.mp4 42.74M

 | | ├──11-实战音乐分类器_代码对单首歌曲进行傅里叶变换_代码对600首音乐文件进行傅里叶变换并保存结果.mp4 49.16M

 | | ├──12-实战音乐分类器_代码读取600首傅里叶变换后的数据_构建训练集并训练模型.mp4 47.67M

 | | ├──13-实战音乐分类器_模型的测试和调优_解决双通道音乐文件的问题.mp4 78.03M

 | | ├──2-从广义线性回归的η推导出来Softmax的公式.mp4 21.35M

 | | ├──3-有了Softmax函数的公式就可以去计算loss_Softmax的Loss函数形式其实就是LR的泛化版本.mp4 33.42M

 | | ├──4-再次证明Softmax损失函数当K=2时就是逻辑回归损失函数.mp4 28.15M

 | | ├──5-证明Softmax公式K=2的时候就是逻辑回归_平移不变性.mp4 13.92M

 | | ├──6-逻辑回归和Softmax回归在多分类任务模型参数上的区别_与算法在选择上的区别.mp4 46.67M

 | | ├──7-实战音乐分类器_讲解需求和读取数据.mp4 32.57M

 | | ├──8-实战音乐分类器_探索不同曲风音乐文件的时间频率图.mp4 52.39M

 | | └──9-实战音乐分类器_傅里叶变换可以帮助我们做什么.mp4 25.13M

 | ├──3&#8211;SVM支持向量机算法

 | | ├──1-SVM与感知机关系_几何距离与函数距离.mp4 114.25M

 | | ├──2-SVM的思想.mp4 55.56M

 | | ├──3-几种SVM_SVM的损失函数.mp4 74.91M

 | | ├──4-数学预备知识_拉格朗日函数.mp4 122.44M

 | | ├──5-硬间隔SVM的两步优化.mp4 102.88M

 | | ├──6-总结硬间隔SVM.mp4 39.01M

 | | ├──7-软间隔SVM和总结流程.mp4 135.76M

 | | ├──8-非线性SVM.mp4 54.43M

 | | └──9-SVM在sklearn中的使用_超参数.mp4 144.30M

 | └──4&#8211;SMO优化算法

 | | ├──1-SVM算法流程总结.mp4 58.36M

 | | ├──10-SVM的SMO实现判断违背条件的α1.mp4 19.23M

 | | ├──11-SVM的SMO实现应用公式计算alphas和b.mp4 20.88M

 | | ├──12-SVM绘制已有数据点和超平面以及边界.mp4 21.13M

 | | ├──13-关于sklearn中的SVM封装的类和超参.mp4 15.47M

 | | ├──14-概率化输出_SVM的合页损失函数_Tensorflow实现GD方式求解SVM.mp4 69.00M

 | | ├──15-OVR和OVO多分类_算法小结_对比逻辑回归.mp4 36.52M

 | | ├──2-SMO算法求解思路_分解成很多个子二次规划问题分别求解.mp4 65.42M

 | | ├──3-SMO将交给它的目标函数变成二元函数进一步变成一元函数.mp4 63.23M

 | | ├──4-对一元函数求极值点_推导出旧的α和新的α的关系.mp4 53.19M

 | | ├──5-将公式467带入导函数进一步简化_对求解出的新的α2进行剪裁.mp4 92.38M

 | | ├──6-再次说明α2如何进行剪裁的思路_根据α2求α1.mp4 37.62M

 | | ├──7-启发式选择两个α.mp4 23.11M

 | | ├──8-如何计算阈值b.mp4 50.18M

 | | └──9-SVM的SMO实现读取数据和计算fx与Ei.mp4 73.44M

 ├──7&#8211;机器学习-无监督学习

 | ├──1&#8211;聚类系列算法

 | | ├──1-KMeans聚类流程_距离测度欧式距离和余弦距离.mp4 173.95M

 | | ├──2-距离测度欧式距离和余弦距离的场景_TFIDF.mp4 153.55M

 | | ├──3-KMeans的一些变形_KMeans的损失函数推导及假设.mp4 167.16M

 | | ├──4-mini-batchKMeans_Canopy聚类_聚类评估指标.mp4 214.69M

 | | ├──5-KMeans代码测试不同情况下的聚类效果.mp4 148.66M

 | | └──6-层次聚类_密度聚类_谱聚类.mp4 264.04M

 | ├──2&#8211;EM算法和GMM高斯混合模型

 | | ├──1-单个高斯分布GM的参数估计.mp4 112.72M

 | | ├──2-理解GMM高斯混合分布的对数似然函数.mp4 95.22M

 | | ├──3-GMM参数估计Πμσ的流程.mp4 112.23M

 | | ├──4-Jensen不等式的应用.mp4 109.17M

 | | ├──5-将EM算法应用到GMM中并且推导出了μ和Σ的公式.mp4 157.57M

 | | ├──6-将EM算法应用到GMM中并且推导出Π的公式.mp4 44.12M

 | | ├──7-GMM前景背景分离.mp4 16.01M

 | | ├──8-通过声音文件利用GMM算法识别性别.mp4 134.39M

 | | └──9-通过声音文件利用GMM算法识别是谁.mp4 51.52M

 | └──3&#8211;PCA降维算法

 | | ├──1-特征选择与特征映射.mp4 49.38M

 | | ├──2-PCA的最大投影方差思路.mp4 186.75M

 | | ├──3-最大投影方差推导_最小投影距离思路.mp4 115.67M

 | | ├──4-SVD其实就可以去实现PCA了.mp4 92.97M

 | | └──5-PCA的几种应用.mp4 54.58M

 ├──8&#8211;机器学习-决策树系列

 | ├──1&#8211;决策树

 | | ├──1-决策树模型的特点.mp4 74.88M

 | | ├──10-绘制决策树模型_寻找最优树深度.mp4 97.10M

 | | ├──11-代码训练回归树拟合SineWave.mp4 93.81M

 | | ├──12-后剪枝的意义.mp4 50.49M

 | | ├──13-CCP代价复杂度后剪枝.mp4 130.67M

 | | ├──14-CCP代价复杂度剪枝_α超参数设定.mp4 62.18M

 | | ├──2-决策树的数学表达.mp4 89.94M

 | | ├──3-如何构建一颗决策树.mp4 84.87M

 | | ├──4-什么是更好的一次划分.mp4 57.02M

 | | ├──5-Gini系数.mp4 107.54M

 | | ├──6-信息增益.mp4 75.26M

 | | ├──7-熵与Gini系数关系_信息增益率.mp4 118.18M

 | | ├──8-预剪枝以及相关超参数.mp4 127.06M

 | | └──9-代码实战决策树对鸢尾花数据集分类.mp4 77.90M

 | ├──2&#8211;集成学习和随机森林

 | | ├──1-不同聚合方式_生成不同弱学习器方式.mp4 80.47M

 | | ├──2-Bagging_Boosting_Stacking.mp4 59.02M

 | | ├──3-随机森林.mp4 108.14M

 | | ├──4-代码实战随机森林对鸢尾花数据集分类.mp4 101.81M

 | | ├──5-OOB袋外数据.mp4 106.07M

 | | ├──6-Adaboost算法思路.mp4 106.30M

 | | ├──7-调整数据权重让权重正确率达到50%.mp4 66.83M

 | | └──8-Adaboost如何调整样本权重和求基模型权重.mp4 90.51M

 | ├──3&#8211;GBDT

 | | ├──1-GBDT试图使用有监督最优化算法梯度下降求解F(x).mp4 65.49M

 | | ├──10-GBDT多分类如何每轮给K颗小树准备要去拟合的负梯度.mp4 72.09M

 | | ├──11-GBDT多分类流程.mp4 73.80M

 | | ├──12-对比GBDT回归、二分类、多分类相同点与不同点.mp4 60.80M

 | | ├──13-GBDT二分类叶子节点分值计算推导.mp4 73.96M

 | | ├──14-GBDT多分类叶子节点分值计算.mp4 54.63M

 | | ├──15-GBDT二分类举例详解.mp4 86.67M

 | | ├──16-GBDT多分类举例详解.mp4 91.71M

 | | ├──17-计算特征重要度进行特征选择.mp4 54.87M

 | | ├──18-GBDT用于特征组合降维.mp4 43.72M

 | | ├──19-特征组合降维在GBDT+LR架构应用.mp4 51.28M

 | | ├──2-GBDT令每个弱学习器f(x)去拟合负梯度.mp4 88.39M

 | | ├──20-GBDT在sklearn中源码剖析_初始化F(x).mp4 115.14M

 | | ├──21-GBDT在sklearn中源码剖析_负梯度计算和叶子节点分值计算.mp4 71.74M

 | | ├──22-GBDT+LR架构训练模型代码实现.mp4 88.40M

 | | ├──23-GBDT+LR架构预测评估代码实现.mp4 66.47M

 | | ├──3-GBDT每棵树都是回归树_准备数据才能训练下一颗小树.mp4 77.36M

 | | ├──4-GBDT应用于回归问题.mp4 84.66M

 | | ├──5-GBDT回归举例_总结.mp4 108.52M

 | | ├──6-GBDT应用于二分类问题.mp4 70.42M

 | | ├──7-GBDT二分类拟合的负梯度依然是残差.mp4 83.81M

 | | ├──8-GBDT中shrinkage学习率和最优树权重ρ可以共存.mp4 61.49M

 | | └──9-GBDT应用于多分类任务.mp4 73.34M

 | └──4&#8211;XGBoost

 | | ├──1-回顾有监督机器学习三要素.mp4 82.52M

 | | ├──10-重新定义树ft和树的复杂度Ω.mp4 77.70M

 | | ├──11-由每个叶子节点重组目标函数Obj.mp4 68.56M

 | | ├──12-推导XGBoost出Wj计算公式_推导评价树好坏的Obj.mp4 72.32M

 | | ├──13-根据Obj收益指导每一次分裂从而学习一棵树结构.mp4 106.69M

 | | ├──14-举例说明从连续型和离散型变量中寻找最佳分裂条件.mp4 73.80M

 | | ├──15-XGBoost中防止过拟合的前剪枝_后剪枝_学习率.mp4 71.21M

 | | ├──16-样本权重对于模型学习的影响.mp4 59.81M

 | | ├──17-总结XGBoost的特性_包括缺失值的处理策略.mp4 101.47M

 | | ├──2-Bias_Variance_Trade-off.mp4 66.00M

 | | ├──3-基于树集成学习4个优点.mp4 91.36M

 | | ├──4-回顾基于树集成学习的模型和参数并举例说明.mp4 93.39M

 | | ├──5-通过目标函数Obj来达到准确率和复杂度平衡.mp4 48.31M

 | | ├──6-Objective_vs_Heuristic.mp4 60.42M

 | | ├──7-得出XGBoost最开始的Obj目标函数.mp4 94.87M

 | | ├──8-推导XGBoost对Loss二阶泰勒展开之后的Obj.mp4 48.62M

 | | └──9-Obj化简常数项_明确训练每颗回归树需要准备gi和hi.mp4 67.39M

 └──9&#8211;机器学习-概率图模型

 | ├──1&#8211;贝叶斯分类

 | | ├──1-朴素贝叶斯分类算法.mp4 126.74M

 | | ├──2-TF-IDF.mp4 53.08M

 | | ├──3-NB代码实现解析.mp4 126.73M

 | | ├──4-sklearn中调用NB_顺便讲解了GridSearchCV.mp4 131.83M

 | | ├──5-语言模型的设计目的_MLE的作用进行参数估计.mp4 107.12M

 | | └──6-贝叶斯网络_马尔可夫链.mp4 38.75M

 | ├──2&#8211;HMM算法

 | | ├──1-HMM隐马的定义.mp4 36.82M

 | | ├──2-HMM隐马的三组参数_三个基本问题.mp4 104.28M

 | | ├──3-HMM预测问题使用前向算法.mp4 44.33M

 | | ├──4-HMM预测问题使用维特比算法.mp4 33.43M

 | | ├──5-HMM复习_明确概率计算问题要解决的目标.mp4 76.05M

 | | ├──6-前向算法来解决概率计算问题.mp4 33.05M

 | | ├──7-Viterbi算法案例详解.mp4 107.12M

 | | └──8-Viterbi算法代码实现.mp4 42.43M

 | └──3&#8211;CRF算法

 | | ├──1-NER与分词和POS的关系_NER的标注策略_NER的主要方法.mp4 127.78M

 | | ├──2-讲解了一下常见的深度学习LSTM+CRF的网络拓扑.mp4 71.88M

 | | ├──3-了解CRF层添加的好处.mp4 105.90M

 | | ├──4-EmissionScore_TransitionScore.mp4 61.33M

 | | ├──5-CRF的目标函数.mp4 23.74M

 | | ├──6-计算CRF真实路径的分数.mp4 50.37M

 | | ├──7-计算CRF所有可能路径的总分数.mp4 135.58M

 | | └──8-通过模型来预测新的句子的序列标签.mp4 83.16M

  